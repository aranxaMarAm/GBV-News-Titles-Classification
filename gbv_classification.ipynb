{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training GBV labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used libraries\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                link state  \\\n",
      "0  https://web.archive.org/web/20200901174745/htt...  CHIH   \n",
      "1  https://web.archive.org/web/20200721132743/htt...  CHIH   \n",
      "2    http://laopcion.com.mx/noticia/98812?archivo=si  CHIH   \n",
      "3  https://web.archive.org/web/20200901181614/htt...  CHIH   \n",
      "4  https://web.archive.org/web/20200901184921/htt...  CHIH   \n",
      "\n",
      "                                               title      frame  \n",
      "0  Imparte fiscalía pláticas preventivas a emplea...   Temático  \n",
      "1  La atropella su pareja y la deja lesionada al ...  Episódico  \n",
      "2  Detienen a chofer de camión urbano por hostiga...  Episódico  \n",
      "3  Inaugura Duarte Centro de Salud y Albergue Cie...   Temático  \n",
      "4  Presentan la conferencia La grandeza de ser mu...   Temático  \n"
     ]
    }
   ],
   "source": [
    "# Load the labeled data\n",
    "file_path = 'gbv_df.xlsx'\n",
    "gbv_df = pd.read_excel(file_path)\n",
    "\n",
    "# Inspect the data\n",
    "print(gbv_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Imparte fiscalía pláticas preventivas a emplea...   \n",
      "1  La atropella su pareja y la deja lesionada al ...   \n",
      "2  Detienen a chofer de camión urbano por hostiga...   \n",
      "3  Inaugura Duarte Centro de Salud y Albergue Cie...   \n",
      "4  Presentan la conferencia La grandeza de ser mu...   \n",
      "\n",
      "                                       cleaned_title  \n",
      "0  imparte fiscala plticas preventivas a empleado...  \n",
      "1  la atropella su pareja y la deja lesionada al ...  \n",
      "2  detienen a chofer de camin urbano por hostigam...  \n",
      "3  inaugura duarte centro de salud y albergue cie...  \n",
      "4  presentan la conferencia la grandeza de ser mu...  \n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove non-alphabetical characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to the 'title' column\n",
    "gbv_df['cleaned_title'] = gbv_df['title'].apply(preprocess_text)\n",
    "\n",
    "# Display the cleaned text\n",
    "print(gbv_df[['title', 'cleaned_title']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean frame labels and remove accents\n",
    "def clean_labels(label):\n",
    "    # Normalize the text to decompose accents\n",
    "    label = unicodedata.normalize('NFD', label)\n",
    "    # Remove diacritics (accents) by filtering characters\n",
    "    label = ''.join(char for char in label if unicodedata.category(char) != 'Mn')\n",
    "    # Convert to lowercase and strip whitespace\n",
    "    label = label.lower().strip()\n",
    "    return label\n",
    "\n",
    "# Apply the cleaning function to the 'frame' column\n",
    "gbv_df['frames'] = gbv_df['frame'].apply(clean_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['episodico' 'tematico']\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and labels (y)\n",
    "X = gbv_df['cleaned_title']\n",
    "y = gbv_df['frames']  \n",
    "\n",
    "# Encode labels if necessary\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)  # Converts to numerical values\n",
    "print(label_encoder.classes_)  # Check the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 777, Test samples: 195\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape (training): (777, 1775)\n"
     ]
    }
   ],
   "source": [
    "# Use TF-IDF for feature extraction\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
    "\n",
    "# Fit the vectorizer on training data and transform both training and test data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"TF-IDF matrix shape (training): {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9128205128205128\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   episodico       0.91      0.93      0.92       103\n",
      "    tematico       0.92      0.89      0.91        92\n",
      "\n",
      "    accuracy                           0.91       195\n",
      "   macro avg       0.91      0.91      0.91       195\n",
      "weighted avg       0.91      0.91      0.91       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model\n",
    "logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logreg.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping for more news titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Base URL and keywords\n",
    "base_url = \"https://8columnas.com.mx/page/{}/?s={}\"\n",
    "keywords = [\"mujer\", \"niña\", \"violencia de genero\", \"feminicidio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://8columnas.com.mx/page/1/?s=mujer\n",
      "Failed to fetch page: https://8columnas.com.mx/page/1/?s=mujer\n",
      "Fetching: https://8columnas.com.mx/page/2/?s=mujer\n",
      "Failed to fetch page: https://8columnas.com.mx/page/2/?s=mujer\n",
      "Fetching: https://8columnas.com.mx/page/3/?s=mujer\n",
      "Failed to fetch page: https://8columnas.com.mx/page/3/?s=mujer\n",
      "Fetching: https://8columnas.com.mx/page/4/?s=mujer\n",
      "Failed to fetch page: https://8columnas.com.mx/page/4/?s=mujer\n",
      "Fetching: https://8columnas.com.mx/page/5/?s=mujer\n",
      "Failed to fetch page: https://8columnas.com.mx/page/5/?s=mujer\n",
      "Fetching: https://8columnas.com.mx/page/6/?s=mujer\n",
      "Failed to fetch page: https://8columnas.com.mx/page/6/?s=mujer\n",
      "Fetching: https://8columnas.com.mx/page/7/?s=mujer\n",
      "Failed to fetch page: https://8columnas.com.mx/page/7/?s=mujer\n",
      "Fetching: https://8columnas.com.mx/page/8/?s=mujer\n",
      "Failed to fetch page: https://8columnas.com.mx/page/8/?s=mujer\n",
      "Fetching: https://8columnas.com.mx/page/9/?s=mujer\n",
      "Failed to fetch page: https://8columnas.com.mx/page/9/?s=mujer\n",
      "Fetching: https://8columnas.com.mx/page/10/?s=mujer\n",
      "Failed to fetch page: https://8columnas.com.mx/page/10/?s=mujer\n",
      "Fetching: https://8columnas.com.mx/page/1/?s=niña\n",
      "Failed to fetch page: https://8columnas.com.mx/page/1/?s=niña\n",
      "Fetching: https://8columnas.com.mx/page/2/?s=niña\n",
      "Failed to fetch page: https://8columnas.com.mx/page/2/?s=niña\n",
      "Fetching: https://8columnas.com.mx/page/3/?s=niña\n",
      "Failed to fetch page: https://8columnas.com.mx/page/3/?s=niña\n",
      "Fetching: https://8columnas.com.mx/page/4/?s=niña\n",
      "Failed to fetch page: https://8columnas.com.mx/page/4/?s=niña\n",
      "Fetching: https://8columnas.com.mx/page/5/?s=niña\n",
      "Failed to fetch page: https://8columnas.com.mx/page/5/?s=niña\n",
      "Fetching: https://8columnas.com.mx/page/6/?s=niña\n",
      "Failed to fetch page: https://8columnas.com.mx/page/6/?s=niña\n",
      "Fetching: https://8columnas.com.mx/page/7/?s=niña\n",
      "Failed to fetch page: https://8columnas.com.mx/page/7/?s=niña\n",
      "Fetching: https://8columnas.com.mx/page/8/?s=niña\n",
      "Failed to fetch page: https://8columnas.com.mx/page/8/?s=niña\n",
      "Fetching: https://8columnas.com.mx/page/9/?s=niña\n",
      "Failed to fetch page: https://8columnas.com.mx/page/9/?s=niña\n",
      "Fetching: https://8columnas.com.mx/page/10/?s=niña\n",
      "Failed to fetch page: https://8columnas.com.mx/page/10/?s=niña\n",
      "Fetching: https://8columnas.com.mx/page/1/?s=violencia de genero\n",
      "Failed to fetch page: https://8columnas.com.mx/page/1/?s=violencia de genero\n",
      "Fetching: https://8columnas.com.mx/page/2/?s=violencia de genero\n",
      "Failed to fetch page: https://8columnas.com.mx/page/2/?s=violencia de genero\n",
      "Fetching: https://8columnas.com.mx/page/3/?s=violencia de genero\n",
      "Failed to fetch page: https://8columnas.com.mx/page/3/?s=violencia de genero\n",
      "Fetching: https://8columnas.com.mx/page/4/?s=violencia de genero\n",
      "Failed to fetch page: https://8columnas.com.mx/page/4/?s=violencia de genero\n",
      "Fetching: https://8columnas.com.mx/page/5/?s=violencia de genero\n",
      "Failed to fetch page: https://8columnas.com.mx/page/5/?s=violencia de genero\n",
      "Fetching: https://8columnas.com.mx/page/6/?s=violencia de genero\n",
      "Failed to fetch page: https://8columnas.com.mx/page/6/?s=violencia de genero\n",
      "Fetching: https://8columnas.com.mx/page/7/?s=violencia de genero\n",
      "Failed to fetch page: https://8columnas.com.mx/page/7/?s=violencia de genero\n",
      "Fetching: https://8columnas.com.mx/page/8/?s=violencia de genero\n",
      "Failed to fetch page: https://8columnas.com.mx/page/8/?s=violencia de genero\n",
      "Fetching: https://8columnas.com.mx/page/9/?s=violencia de genero\n",
      "Failed to fetch page: https://8columnas.com.mx/page/9/?s=violencia de genero\n",
      "Fetching: https://8columnas.com.mx/page/10/?s=violencia de genero\n",
      "Failed to fetch page: https://8columnas.com.mx/page/10/?s=violencia de genero\n",
      "Fetching: https://8columnas.com.mx/page/1/?s=feminicidio\n",
      "Failed to fetch page: https://8columnas.com.mx/page/1/?s=feminicidio\n",
      "Fetching: https://8columnas.com.mx/page/2/?s=feminicidio\n",
      "Failed to fetch page: https://8columnas.com.mx/page/2/?s=feminicidio\n",
      "Fetching: https://8columnas.com.mx/page/3/?s=feminicidio\n",
      "Failed to fetch page: https://8columnas.com.mx/page/3/?s=feminicidio\n",
      "Fetching: https://8columnas.com.mx/page/4/?s=feminicidio\n",
      "Failed to fetch page: https://8columnas.com.mx/page/4/?s=feminicidio\n",
      "Fetching: https://8columnas.com.mx/page/5/?s=feminicidio\n",
      "Failed to fetch page: https://8columnas.com.mx/page/5/?s=feminicidio\n",
      "Fetching: https://8columnas.com.mx/page/6/?s=feminicidio\n",
      "Failed to fetch page: https://8columnas.com.mx/page/6/?s=feminicidio\n",
      "Fetching: https://8columnas.com.mx/page/7/?s=feminicidio\n",
      "Failed to fetch page: https://8columnas.com.mx/page/7/?s=feminicidio\n",
      "Fetching: https://8columnas.com.mx/page/8/?s=feminicidio\n",
      "Failed to fetch page: https://8columnas.com.mx/page/8/?s=feminicidio\n",
      "Fetching: https://8columnas.com.mx/page/9/?s=feminicidio\n",
      "Failed to fetch page: https://8columnas.com.mx/page/9/?s=feminicidio\n",
      "Fetching: https://8columnas.com.mx/page/10/?s=feminicidio\n",
      "Failed to fetch page: https://8columnas.com.mx/page/10/?s=feminicidio\n",
      "Scraping completed. Titles saved to extracted_titles.csv.\n"
     ]
    }
   ],
   "source": [
    "# Function to extract titles from a single page\n",
    "def extract_titles(page_url):\n",
    "    response = requests.get(page_url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch page: {page_url}\")\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Assuming article titles are within <h2> or similar tags\n",
    "    # Adjust the selector as per the website's structure\n",
    "    titles = soup.select('h2.entry-title a')  # Example: change this selector if needed\n",
    "    return [title.get_text(strip=True) for title in titles]\n",
    "\n",
    "# Iterate through pages and keywords\n",
    "all_data = []\n",
    "for keyword in keywords:\n",
    "    for page in range(1, 11):  # First 10 pages\n",
    "        url = base_url.format(page, keyword)\n",
    "        print(f\"Fetching: {url}\")\n",
    "        titles = extract_titles(url)\n",
    "        \n",
    "        # Append results with keyword information\n",
    "        for title in titles:\n",
    "            all_data.append({\"keyword\": keyword, \"title\": title})\n",
    "\n",
    "# Convert the results to a DataFrame and save to a CSV\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv('8c_titles.csv', index=False)\n",
    "print(\"Scraping completed. Titles saved to extracted_titles.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La Opción de Chihuahua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
